{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01 - GAN Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0grGvEVQDbkw",
        "colab_type": "text"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2i0MhNfzg5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b208035c-cc82-4169-9746-1ea964282d38"
      },
      "source": [
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVSk1nlDZK7",
        "colab_type": "text"
      },
      "source": [
        "## Defining the Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTdcq9fU1Uxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_discriminator(in_shape=(160,160,3)):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozntQuwdDT2f",
        "colab_type": "text"
      },
      "source": [
        "## Defining the generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGLBv2nj2Tsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_generator(latent_dim):\n",
        "    model = Sequential()\n",
        "    n_nodes = 128 * 5 * 5\n",
        "\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((5, 5, 128)))\n",
        "    \n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    \n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2D(3, (5,5), activation='tanh', padding='same'))\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHHcZMkLDwkF",
        "colab_type": "text"
      },
      "source": [
        "## Defining the generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLH4XBS9DK1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "    d_model.trainable = False\n",
        "    model = Sequential()\n",
        "    model.add(g_model)\n",
        "    model.add(d_model)\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CcyVnF_Dog-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_real_samples():\n",
        "    path = './drive/My Drive/faces.npz'\n",
        "    data = load(path)\n",
        "    X = data['arr_0']\n",
        "    X = X.astype('float32')\n",
        "    X = (X - 127.5) / 127.5\n",
        "    return X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzZT49i6EQ_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[ix]\n",
        "    y = 0.9 * ones((n_samples, 1)) + 0.2 * randn(n_samples).reshape((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdbGJ-hdE1gK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZHMWvM4E1cO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = g_model.predict(x_input)\n",
        "    y = 0.1 * ones((n_samples, 1)) + 0.2 * randn(n_samples).reshape((n_samples, 1))\n",
        "    return X, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO55sYyqE1YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_plot(examples, epoch, n=10):\n",
        "    examples = (examples + 1) / 2.0\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(examples[i])\n",
        "        filename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "    pyplot.savefig(filename)\n",
        "    pyplot.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-WHtjzjE5l3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):\n",
        "    X_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "    save_plot(x_fake, epoch)\n",
        "    filename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "    g_model.save(filename)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61cJxjYzE9Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=64):\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "    for i in range(n_epochs):\n",
        "        for j in range(bat_per_epo):\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            y_gan = ones((n_batch, 1))\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
        "                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
        "        if (i+1) % 2 == 0:\n",
        "            summarize_performance(i, g_model, d_model, dataset, latent_dim)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWxyWn5QE9Dw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11aa0170-5eba-4f1d-855b-f10eec8cedcb"
      },
      "source": [
        "latent_dim = 200\n",
        "d_model = define_discriminator()\n",
        "g_model = define_generator(latent_dim)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "dataset = load_real_samples()\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">1, 1/156, d1=0.691, d2=0.695 g=0.692\n",
            ">1, 2/156, d1=0.541, d2=0.699 g=0.691\n",
            ">1, 3/156, d1=0.383, d2=0.695 g=0.694\n",
            ">1, 4/156, d1=0.393, d2=0.694 g=0.694\n",
            ">1, 5/156, d1=0.112, d2=0.721 g=0.692\n",
            ">1, 6/156, d1=0.360, d2=0.706 g=0.695\n",
            ">1, 7/156, d1=0.456, d2=0.725 g=0.677\n",
            ">1, 8/156, d1=0.301, d2=0.851 g=0.688\n",
            ">1, 9/156, d1=0.329, d2=0.701 g=0.747\n",
            ">1, 10/156, d1=0.552, d2=0.674 g=0.761\n",
            ">1, 11/156, d1=0.557, d2=0.675 g=0.770\n",
            ">1, 12/156, d1=0.360, d2=0.646 g=0.907\n",
            ">1, 13/156, d1=0.267, d2=0.591 g=1.036\n",
            ">1, 14/156, d1=0.671, d2=0.632 g=0.775\n",
            ">1, 15/156, d1=0.502, d2=0.648 g=0.773\n",
            ">1, 16/156, d1=0.515, d2=0.617 g=0.852\n",
            ">1, 17/156, d1=0.353, d2=0.540 g=1.090\n",
            ">1, 18/156, d1=0.330, d2=0.458 g=1.838\n",
            ">1, 19/156, d1=0.310, d2=0.382 g=2.334\n",
            ">1, 20/156, d1=0.295, d2=0.364 g=2.211\n",
            ">1, 21/156, d1=0.523, d2=0.413 g=4.096\n",
            ">1, 22/156, d1=0.401, d2=0.958 g=1.863\n",
            ">1, 23/156, d1=0.357, d2=0.525 g=1.156\n",
            ">1, 24/156, d1=0.472, d2=0.520 g=1.375\n",
            ">1, 25/156, d1=0.393, d2=0.411 g=2.093\n",
            ">1, 26/156, d1=0.354, d2=0.333 g=2.394\n",
            ">1, 27/156, d1=0.460, d2=0.338 g=2.269\n",
            ">1, 28/156, d1=0.373, d2=0.473 g=1.927\n",
            ">1, 29/156, d1=0.477, d2=0.229 g=2.186\n",
            ">1, 30/156, d1=0.397, d2=0.088 g=3.287\n",
            ">1, 31/156, d1=0.234, d2=0.557 g=2.584\n",
            ">1, 32/156, d1=0.378, d2=0.256 g=2.171\n",
            ">1, 33/156, d1=0.318, d2=0.232 g=2.522\n",
            ">1, 34/156, d1=0.287, d2=0.178 g=3.006\n",
            ">1, 35/156, d1=0.486, d2=0.459 g=2.251\n",
            ">1, 36/156, d1=0.313, d2=0.400 g=2.308\n",
            ">1, 37/156, d1=0.353, d2=0.334 g=3.380\n",
            ">1, 38/156, d1=0.332, d2=0.074 g=4.778\n",
            ">1, 39/156, d1=0.328, d2=0.412 g=2.228\n",
            ">1, 40/156, d1=0.273, d2=0.367 g=1.919\n",
            ">1, 41/156, d1=0.382, d2=0.312 g=2.517\n",
            ">1, 42/156, d1=0.366, d2=0.507 g=1.786\n",
            ">1, 43/156, d1=0.345, d2=0.414 g=2.027\n",
            ">1, 44/156, d1=0.179, d2=0.243 g=3.007\n",
            ">1, 45/156, d1=0.389, d2=0.411 g=2.136\n",
            ">1, 46/156, d1=0.373, d2=0.437 g=1.701\n",
            ">1, 47/156, d1=0.210, d2=0.416 g=1.825\n",
            ">1, 48/156, d1=0.296, d2=0.362 g=2.131\n",
            ">1, 49/156, d1=0.534, d2=0.365 g=2.162\n",
            ">1, 50/156, d1=0.482, d2=0.352 g=2.162\n",
            ">1, 51/156, d1=0.382, d2=0.287 g=2.439\n",
            ">1, 52/156, d1=0.426, d2=0.168 g=3.268\n",
            ">1, 53/156, d1=0.272, d2=0.389 g=2.344\n",
            ">1, 54/156, d1=0.349, d2=0.328 g=2.403\n",
            ">1, 55/156, d1=0.412, d2=0.286 g=2.703\n",
            ">1, 56/156, d1=0.454, d2=0.304 g=2.473\n",
            ">1, 57/156, d1=0.426, d2=0.342 g=4.141\n",
            ">1, 58/156, d1=0.490, d2=0.333 g=2.102\n",
            ">1, 59/156, d1=0.248, d2=0.730 g=1.910\n",
            ">1, 60/156, d1=0.299, d2=0.325 g=5.772\n",
            ">1, 61/156, d1=1.446, d2=0.640 g=0.888\n",
            ">1, 62/156, d1=0.958, d2=0.613 g=0.924\n",
            ">1, 63/156, d1=0.528, d2=0.598 g=0.902\n",
            ">1, 64/156, d1=1.182, d2=0.569 g=0.996\n",
            ">1, 65/156, d1=0.569, d2=0.504 g=1.531\n",
            ">1, 66/156, d1=0.343, d2=0.330 g=2.782\n",
            ">1, 67/156, d1=0.307, d2=0.507 g=1.748\n",
            ">1, 68/156, d1=0.340, d2=0.484 g=1.922\n",
            ">1, 69/156, d1=0.348, d2=0.405 g=2.150\n",
            ">1, 70/156, d1=0.319, d2=0.299 g=2.392\n",
            ">1, 71/156, d1=0.503, d2=0.369 g=1.781\n",
            ">1, 72/156, d1=0.272, d2=0.411 g=3.355\n",
            ">1, 73/156, d1=0.207, d2=0.241 g=4.014\n",
            ">1, 74/156, d1=0.396, d2=0.290 g=2.596\n",
            ">1, 75/156, d1=0.325, d2=0.247 g=2.376\n",
            ">1, 76/156, d1=0.410, d2=0.219 g=2.789\n",
            ">1, 77/156, d1=0.397, d2=0.337 g=2.412\n",
            ">1, 78/156, d1=0.363, d2=0.292 g=2.773\n",
            ">1, 79/156, d1=0.233, d2=0.237 g=3.034\n",
            ">1, 80/156, d1=0.441, d2=0.392 g=5.264\n",
            ">1, 81/156, d1=0.366, d2=0.673 g=1.700\n",
            ">1, 82/156, d1=0.347, d2=0.558 g=1.353\n",
            ">1, 83/156, d1=0.361, d2=0.312 g=1.986\n",
            ">1, 84/156, d1=0.327, d2=0.303 g=2.674\n",
            ">1, 85/156, d1=0.224, d2=0.436 g=2.117\n",
            ">1, 86/156, d1=0.406, d2=0.456 g=1.656\n",
            ">1, 87/156, d1=0.425, d2=0.362 g=1.935\n",
            ">1, 88/156, d1=0.330, d2=0.391 g=2.252\n",
            ">1, 89/156, d1=0.340, d2=0.210 g=2.713\n",
            ">1, 90/156, d1=0.285, d2=0.323 g=2.600\n",
            ">1, 91/156, d1=0.288, d2=0.298 g=2.325\n",
            ">1, 92/156, d1=0.165, d2=0.298 g=2.693\n",
            ">1, 93/156, d1=0.207, d2=0.351 g=2.283\n",
            ">1, 94/156, d1=0.507, d2=0.559 g=4.641\n",
            ">1, 95/156, d1=1.017, d2=0.413 g=1.465\n",
            ">1, 96/156, d1=0.345, d2=0.536 g=2.349\n",
            ">1, 97/156, d1=0.293, d2=0.332 g=2.409\n",
            ">1, 98/156, d1=0.404, d2=0.241 g=2.699\n",
            ">1, 99/156, d1=0.309, d2=0.446 g=2.131\n",
            ">1, 100/156, d1=0.512, d2=0.352 g=1.879\n",
            ">1, 101/156, d1=0.385, d2=0.407 g=2.166\n",
            ">1, 102/156, d1=0.347, d2=0.645 g=3.411\n",
            ">1, 103/156, d1=0.384, d2=0.421 g=9.710\n",
            ">1, 104/156, d1=4.426, d2=0.722 g=0.751\n",
            ">1, 105/156, d1=1.973, d2=0.652 g=0.788\n",
            ">1, 106/156, d1=1.103, d2=0.648 g=0.807\n",
            ">1, 107/156, d1=0.497, d2=0.598 g=0.883\n",
            ">1, 108/156, d1=0.367, d2=0.555 g=1.046\n",
            ">1, 109/156, d1=0.163, d2=0.462 g=1.680\n",
            ">1, 110/156, d1=0.469, d2=0.347 g=2.617\n",
            ">1, 111/156, d1=0.395, d2=0.319 g=2.530\n",
            ">1, 112/156, d1=0.353, d2=0.337 g=2.356\n",
            ">1, 113/156, d1=0.275, d2=0.391 g=3.430\n",
            ">1, 114/156, d1=0.422, d2=0.203 g=4.698\n",
            ">1, 115/156, d1=0.258, d2=0.887 g=10.554\n",
            ">1, 116/156, d1=1.117, d2=0.474 g=1.254\n",
            ">1, 117/156, d1=1.238, d2=0.654 g=0.858\n",
            ">1, 118/156, d1=0.478, d2=0.704 g=0.736\n",
            ">1, 119/156, d1=0.477, d2=0.714 g=0.761\n",
            ">1, 120/156, d1=0.384, d2=0.625 g=0.959\n",
            ">1, 121/156, d1=0.347, d2=0.517 g=1.254\n",
            ">1, 122/156, d1=0.390, d2=0.419 g=1.816\n",
            ">1, 123/156, d1=0.309, d2=0.354 g=2.135\n",
            ">1, 124/156, d1=0.206, d2=0.419 g=2.093\n",
            ">1, 125/156, d1=0.417, d2=0.423 g=1.845\n",
            ">1, 126/156, d1=0.407, d2=0.359 g=2.537\n",
            ">1, 127/156, d1=0.336, d2=0.414 g=2.146\n",
            ">1, 128/156, d1=0.388, d2=0.730 g=2.270\n",
            ">1, 129/156, d1=0.398, d2=0.266 g=9.610\n",
            ">1, 130/156, d1=0.390, d2=0.796 g=2.262\n",
            ">1, 131/156, d1=0.319, d2=0.570 g=1.305\n",
            ">1, 132/156, d1=0.372, d2=0.385 g=2.139\n",
            ">1, 133/156, d1=0.242, d2=0.311 g=2.628\n",
            ">1, 134/156, d1=0.457, d2=0.303 g=2.602\n",
            ">1, 135/156, d1=0.402, d2=0.395 g=2.786\n",
            ">1, 136/156, d1=0.351, d2=0.285 g=4.375\n",
            ">1, 137/156, d1=0.184, d2=0.275 g=1.322\n",
            ">1, 138/156, d1=0.401, d2=0.970 g=1.660\n",
            ">1, 139/156, d1=0.442, d2=0.331 g=4.947\n",
            ">1, 140/156, d1=0.355, d2=0.559 g=1.322\n",
            ">1, 141/156, d1=0.296, d2=0.642 g=0.884\n",
            ">1, 142/156, d1=0.292, d2=0.580 g=1.155\n",
            ">1, 143/156, d1=0.590, d2=0.468 g=1.745\n",
            ">1, 144/156, d1=0.465, d2=0.343 g=2.292\n",
            ">1, 145/156, d1=0.462, d2=0.323 g=2.426\n",
            ">1, 146/156, d1=0.276, d2=0.402 g=2.212\n",
            ">1, 147/156, d1=0.307, d2=0.367 g=2.529\n",
            ">1, 148/156, d1=0.302, d2=0.444 g=2.571\n",
            ">1, 149/156, d1=0.330, d2=0.611 g=3.299\n",
            ">1, 150/156, d1=0.350, d2=0.304 g=12.482\n",
            ">1, 151/156, d1=0.619, d2=0.342 g=1.543\n",
            ">1, 152/156, d1=0.373, d2=0.703 g=2.100\n",
            ">1, 153/156, d1=0.389, d2=0.311 g=3.347\n",
            ">1, 154/156, d1=0.566, d2=0.590 g=1.273\n",
            ">1, 155/156, d1=0.271, d2=0.525 g=3.800\n",
            ">1, 156/156, d1=0.387, d2=0.341 g=2.689\n",
            ">2, 1/156, d1=0.597, d2=0.624 g=0.970\n",
            ">2, 2/156, d1=0.330, d2=0.553 g=1.333\n",
            ">2, 3/156, d1=0.423, d2=0.514 g=1.639\n",
            ">2, 4/156, d1=0.316, d2=0.349 g=2.421\n",
            ">2, 5/156, d1=0.332, d2=0.316 g=2.324\n",
            ">2, 6/156, d1=0.490, d2=0.334 g=2.107\n",
            ">2, 7/156, d1=0.297, d2=0.354 g=2.246\n",
            ">2, 8/156, d1=0.392, d2=0.358 g=2.248\n",
            ">2, 9/156, d1=0.241, d2=0.401 g=2.865\n",
            ">2, 10/156, d1=0.462, d2=0.378 g=1.997\n",
            ">2, 11/156, d1=0.227, d2=0.394 g=2.739\n",
            ">2, 12/156, d1=0.403, d2=0.390 g=2.011\n",
            ">2, 13/156, d1=0.424, d2=0.414 g=2.970\n",
            ">2, 14/156, d1=0.352, d2=0.267 g=2.407\n",
            ">2, 15/156, d1=0.464, d2=0.433 g=1.888\n",
            ">2, 16/156, d1=0.415, d2=0.404 g=2.321\n",
            ">2, 17/156, d1=0.381, d2=0.277 g=3.382\n",
            ">2, 18/156, d1=0.321, d2=0.227 g=3.004\n",
            ">2, 19/156, d1=0.266, d2=0.397 g=1.604\n",
            ">2, 20/156, d1=0.352, d2=0.525 g=2.598\n",
            ">2, 21/156, d1=0.379, d2=0.419 g=2.018\n",
            ">2, 22/156, d1=0.335, d2=0.379 g=2.310\n",
            ">2, 23/156, d1=0.422, d2=0.470 g=1.913\n",
            ">2, 24/156, d1=0.340, d2=0.270 g=2.871\n",
            ">2, 25/156, d1=0.321, d2=0.419 g=2.511\n",
            ">2, 26/156, d1=0.328, d2=0.475 g=1.626\n",
            ">2, 27/156, d1=0.439, d2=0.344 g=2.252\n",
            ">2, 28/156, d1=0.360, d2=0.324 g=2.543\n",
            ">2, 29/156, d1=0.400, d2=0.405 g=1.999\n",
            ">2, 30/156, d1=0.215, d2=0.372 g=2.172\n",
            ">2, 31/156, d1=0.348, d2=0.313 g=2.475\n",
            ">2, 32/156, d1=0.444, d2=0.260 g=2.763\n",
            ">2, 33/156, d1=0.347, d2=0.192 g=3.361\n",
            ">2, 34/156, d1=0.246, d2=0.314 g=2.214\n",
            ">2, 35/156, d1=0.556, d2=0.520 g=4.103\n",
            ">2, 36/156, d1=0.546, d2=0.434 g=1.833\n",
            ">2, 37/156, d1=0.257, d2=0.392 g=1.850\n",
            ">2, 38/156, d1=0.364, d2=0.391 g=2.055\n",
            ">2, 39/156, d1=0.400, d2=0.458 g=1.737\n",
            ">2, 40/156, d1=0.495, d2=0.449 g=1.810\n",
            ">2, 41/156, d1=0.488, d2=0.369 g=2.512\n",
            ">2, 42/156, d1=0.415, d2=0.294 g=2.598\n",
            ">2, 43/156, d1=0.248, d2=0.196 g=3.211\n",
            ">2, 44/156, d1=0.283, d2=0.242 g=2.696\n",
            ">2, 45/156, d1=0.406, d2=0.472 g=1.115\n",
            ">2, 46/156, d1=0.320, d2=0.647 g=2.356\n",
            ">2, 47/156, d1=0.333, d2=0.463 g=2.023\n",
            ">2, 48/156, d1=0.477, d2=0.431 g=1.932\n",
            ">2, 49/156, d1=0.368, d2=0.254 g=4.732\n",
            ">2, 50/156, d1=0.156, d2=0.386 g=2.214\n",
            ">2, 51/156, d1=0.439, d2=0.335 g=2.161\n",
            ">2, 52/156, d1=0.258, d2=0.233 g=3.023\n",
            ">2, 53/156, d1=0.487, d2=0.410 g=2.040\n",
            ">2, 54/156, d1=0.388, d2=0.431 g=1.745\n",
            ">2, 55/156, d1=0.434, d2=0.417 g=2.056\n",
            ">2, 56/156, d1=0.293, d2=0.364 g=2.237\n",
            ">2, 57/156, d1=0.303, d2=0.334 g=2.657\n",
            ">2, 58/156, d1=0.485, d2=0.445 g=1.916\n",
            ">2, 59/156, d1=0.307, d2=0.774 g=2.466\n",
            ">2, 60/156, d1=0.248, d2=0.450 g=6.203\n",
            ">2, 61/156, d1=0.836, d2=0.342 g=2.975\n",
            ">2, 62/156, d1=0.418, d2=0.550 g=8.618\n",
            ">2, 63/156, d1=0.421, d2=0.480 g=2.634\n",
            ">2, 64/156, d1=0.419, d2=0.494 g=2.789\n",
            ">2, 65/156, d1=0.294, d2=0.314 g=2.891\n",
            ">2, 66/156, d1=0.447, d2=0.376 g=1.973\n",
            ">2, 67/156, d1=0.396, d2=0.419 g=1.858\n",
            ">2, 68/156, d1=0.403, d2=0.321 g=2.455\n",
            ">2, 69/156, d1=0.310, d2=0.368 g=2.491\n",
            ">2, 70/156, d1=0.437, d2=0.318 g=2.905\n",
            ">2, 71/156, d1=0.371, d2=0.303 g=4.022\n",
            ">2, 72/156, d1=0.436, d2=0.351 g=2.522\n",
            ">2, 73/156, d1=0.398, d2=0.918 g=2.128\n",
            ">2, 74/156, d1=0.435, d2=0.347 g=3.643\n",
            ">2, 75/156, d1=0.388, d2=0.356 g=5.055\n",
            ">2, 76/156, d1=0.519, d2=0.444 g=3.799\n",
            ">2, 77/156, d1=0.354, d2=0.379 g=2.751\n",
            ">2, 78/156, d1=0.585, d2=0.429 g=2.134\n",
            ">2, 79/156, d1=0.389, d2=0.377 g=2.505\n",
            ">2, 80/156, d1=0.267, d2=0.439 g=2.506\n",
            ">2, 81/156, d1=0.366, d2=0.407 g=3.323\n",
            ">2, 82/156, d1=0.281, d2=0.477 g=2.110\n",
            ">2, 83/156, d1=0.667, d2=0.645 g=1.662\n",
            ">2, 84/156, d1=0.446, d2=0.383 g=2.334\n",
            ">2, 85/156, d1=0.296, d2=0.220 g=3.031\n",
            ">2, 86/156, d1=0.367, d2=0.395 g=2.232\n",
            ">2, 87/156, d1=0.513, d2=0.345 g=2.492\n",
            ">2, 88/156, d1=0.396, d2=0.207 g=3.995\n",
            ">2, 89/156, d1=0.418, d2=0.370 g=2.918\n",
            ">2, 90/156, d1=0.506, d2=0.384 g=4.415\n",
            ">2, 91/156, d1=0.633, d2=0.487 g=4.856\n",
            ">2, 92/156, d1=0.557, d2=0.550 g=2.773\n",
            ">2, 93/156, d1=0.234, d2=0.101 g=4.427\n",
            ">2, 94/156, d1=0.422, d2=0.267 g=3.477\n",
            ">2, 95/156, d1=0.304, d2=0.437 g=6.001\n",
            ">2, 96/156, d1=0.649, d2=0.384 g=2.606\n",
            ">2, 97/156, d1=0.289, d2=0.270 g=3.693\n",
            ">2, 98/156, d1=0.335, d2=0.395 g=2.953\n",
            ">2, 99/156, d1=0.662, d2=0.386 g=3.367\n",
            ">2, 100/156, d1=0.632, d2=0.509 g=1.532\n",
            ">2, 101/156, d1=0.247, d2=0.693 g=2.808\n",
            ">2, 102/156, d1=0.345, d2=0.124 g=4.946\n",
            ">2, 103/156, d1=0.651, d2=0.410 g=1.788\n",
            ">2, 104/156, d1=0.308, d2=0.788 g=3.517\n",
            ">2, 105/156, d1=0.809, d2=0.383 g=1.774\n",
            ">2, 106/156, d1=0.393, d2=0.349 g=2.375\n",
            ">2, 107/156, d1=0.337, d2=0.389 g=2.484\n",
            ">2, 108/156, d1=0.459, d2=0.427 g=2.113\n",
            ">2, 109/156, d1=0.389, d2=0.293 g=3.853\n",
            ">2, 110/156, d1=0.740, d2=0.431 g=1.586\n",
            ">2, 111/156, d1=0.510, d2=0.479 g=2.000\n",
            ">2, 112/156, d1=0.303, d2=0.334 g=2.655\n",
            ">2, 113/156, d1=0.507, d2=0.457 g=1.986\n",
            ">2, 114/156, d1=0.366, d2=0.467 g=3.572\n",
            ">2, 115/156, d1=0.618, d2=0.286 g=3.060\n",
            ">2, 116/156, d1=0.413, d2=0.364 g=3.262\n",
            ">2, 117/156, d1=0.473, d2=0.201 g=3.849\n",
            ">2, 118/156, d1=0.438, d2=0.380 g=1.704\n",
            ">2, 119/156, d1=0.377, d2=0.692 g=2.491\n",
            ">2, 120/156, d1=0.466, d2=0.494 g=1.907\n",
            ">2, 121/156, d1=0.305, d2=0.401 g=1.883\n",
            ">2, 122/156, d1=0.463, d2=0.354 g=2.182\n",
            ">2, 123/156, d1=0.429, d2=0.368 g=2.239\n",
            ">2, 124/156, d1=0.258, d2=0.237 g=3.003\n",
            ">2, 125/156, d1=0.521, d2=0.291 g=2.570\n",
            ">2, 126/156, d1=0.387, d2=0.382 g=1.971\n",
            ">2, 127/156, d1=0.384, d2=0.293 g=2.827\n",
            ">2, 128/156, d1=0.362, d2=0.374 g=2.326\n",
            ">2, 129/156, d1=0.416, d2=0.292 g=2.706\n",
            ">2, 130/156, d1=0.471, d2=0.392 g=2.130\n",
            ">2, 131/156, d1=0.414, d2=0.341 g=2.572\n",
            ">2, 132/156, d1=0.273, d2=0.406 g=2.211\n",
            ">2, 133/156, d1=0.339, d2=0.352 g=2.071\n",
            ">2, 134/156, d1=0.455, d2=0.411 g=2.132\n",
            ">2, 135/156, d1=0.359, d2=0.450 g=1.918\n",
            ">2, 136/156, d1=0.329, d2=0.468 g=1.820\n",
            ">2, 137/156, d1=0.305, d2=0.430 g=2.670\n",
            ">2, 138/156, d1=0.441, d2=0.431 g=1.960\n",
            ">2, 139/156, d1=0.296, d2=0.519 g=2.014\n",
            ">2, 140/156, d1=0.441, d2=0.218 g=3.538\n",
            ">2, 141/156, d1=0.391, d2=0.416 g=1.750\n",
            ">2, 142/156, d1=0.488, d2=0.543 g=2.612\n",
            ">2, 143/156, d1=0.416, d2=0.356 g=2.806\n",
            ">2, 144/156, d1=0.377, d2=0.390 g=1.905\n",
            ">2, 145/156, d1=0.364, d2=0.386 g=2.224\n",
            ">2, 146/156, d1=0.258, d2=0.280 g=2.916\n",
            ">2, 147/156, d1=0.340, d2=0.408 g=2.315\n",
            ">2, 148/156, d1=0.406, d2=0.428 g=2.344\n",
            ">2, 149/156, d1=0.347, d2=0.377 g=2.256\n",
            ">2, 150/156, d1=0.294, d2=0.422 g=1.885\n",
            ">2, 151/156, d1=0.362, d2=0.462 g=2.673\n",
            ">2, 152/156, d1=0.249, d2=0.418 g=1.749\n",
            ">2, 153/156, d1=0.195, d2=0.546 g=4.045\n",
            ">2, 154/156, d1=0.626, d2=0.562 g=2.688\n",
            ">2, 155/156, d1=0.573, d2=0.640 g=1.298\n",
            ">2, 156/156, d1=0.340, d2=0.399 g=2.022\n",
            ">Accuracy real: 0%, fake: 0%\n",
            ">3, 1/156, d1=0.314, d2=0.317 g=2.553\n",
            ">3, 2/156, d1=0.401, d2=0.416 g=1.939\n",
            ">3, 3/156, d1=0.509, d2=0.524 g=1.678\n",
            ">3, 4/156, d1=0.465, d2=0.439 g=1.950\n",
            ">3, 5/156, d1=0.378, d2=0.318 g=2.917\n",
            ">3, 6/156, d1=0.353, d2=0.546 g=1.451\n",
            ">3, 7/156, d1=0.524, d2=0.647 g=1.645\n",
            ">3, 8/156, d1=0.502, d2=0.259 g=3.045\n",
            ">3, 9/156, d1=0.468, d2=0.469 g=2.107\n",
            ">3, 10/156, d1=0.344, d2=0.354 g=2.359\n",
            ">3, 11/156, d1=0.328, d2=0.394 g=2.326\n",
            ">3, 12/156, d1=0.397, d2=0.265 g=2.653\n",
            ">3, 13/156, d1=0.432, d2=0.398 g=2.150\n",
            ">3, 14/156, d1=0.431, d2=0.396 g=2.273\n",
            ">3, 15/156, d1=0.448, d2=0.411 g=3.743\n",
            ">3, 16/156, d1=1.416, d2=0.571 g=2.453\n",
            ">3, 17/156, d1=0.307, d2=0.271 g=3.823\n",
            ">3, 18/156, d1=0.469, d2=0.327 g=2.389\n",
            ">3, 19/156, d1=0.485, d2=0.548 g=3.497\n",
            ">3, 20/156, d1=0.528, d2=0.714 g=2.289\n",
            ">3, 21/156, d1=0.349, d2=0.286 g=2.541\n",
            ">3, 22/156, d1=0.393, d2=0.360 g=2.223\n",
            ">3, 23/156, d1=0.169, d2=0.401 g=2.546\n",
            ">3, 24/156, d1=0.581, d2=0.412 g=2.379\n",
            ">3, 25/156, d1=0.539, d2=0.578 g=2.278\n",
            ">3, 26/156, d1=0.425, d2=0.420 g=2.663\n",
            ">3, 27/156, d1=0.548, d2=0.356 g=3.124\n",
            ">3, 28/156, d1=0.486, d2=0.453 g=2.724\n",
            ">3, 29/156, d1=0.334, d2=0.375 g=3.296\n",
            ">3, 30/156, d1=0.516, d2=0.388 g=4.740\n",
            ">3, 31/156, d1=0.431, d2=0.401 g=1.397\n",
            ">3, 32/156, d1=0.488, d2=1.345 g=4.087\n",
            ">3, 33/156, d1=0.520, d2=0.339 g=3.091\n",
            ">3, 34/156, d1=0.481, d2=0.484 g=1.632\n",
            ">3, 35/156, d1=0.402, d2=0.430 g=2.093\n",
            ">3, 36/156, d1=0.312, d2=0.338 g=2.672\n",
            ">3, 37/156, d1=0.335, d2=0.250 g=3.048\n",
            ">3, 38/156, d1=0.339, d2=0.437 g=2.817\n",
            ">3, 39/156, d1=0.474, d2=0.441 g=3.858\n",
            ">3, 40/156, d1=0.391, d2=0.508 g=2.727\n",
            ">3, 41/156, d1=0.374, d2=0.405 g=3.097\n",
            ">3, 42/156, d1=0.303, d2=0.669 g=7.521\n",
            ">3, 43/156, d1=1.697, d2=0.769 g=1.466\n",
            ">3, 44/156, d1=0.223, d2=0.357 g=2.581\n",
            ">3, 45/156, d1=0.593, d2=0.400 g=1.971\n",
            ">3, 46/156, d1=0.465, d2=0.497 g=1.302\n",
            ">3, 47/156, d1=0.496, d2=0.489 g=1.706\n",
            ">3, 48/156, d1=0.489, d2=0.428 g=1.975\n",
            ">3, 49/156, d1=0.495, d2=0.395 g=2.110\n",
            ">3, 50/156, d1=0.454, d2=0.399 g=2.080\n",
            ">3, 51/156, d1=0.417, d2=0.307 g=2.774\n",
            ">3, 52/156, d1=0.745, d2=0.456 g=1.800\n",
            ">3, 53/156, d1=0.494, d2=0.387 g=1.931\n",
            ">3, 54/156, d1=0.566, d2=0.398 g=2.081\n",
            ">3, 55/156, d1=0.333, d2=0.421 g=1.984\n",
            ">3, 56/156, d1=0.629, d2=0.471 g=1.758\n",
            ">3, 57/156, d1=0.637, d2=0.440 g=1.796\n",
            ">3, 58/156, d1=0.644, d2=0.300 g=2.234\n",
            ">3, 59/156, d1=0.530, d2=0.306 g=2.454\n",
            ">3, 60/156, d1=0.455, d2=0.478 g=2.006\n",
            ">3, 61/156, d1=0.445, d2=0.501 g=2.111\n",
            ">3, 62/156, d1=0.423, d2=0.496 g=1.915\n",
            ">3, 63/156, d1=0.498, d2=0.578 g=1.769\n",
            ">3, 64/156, d1=0.486, d2=0.475 g=2.045\n",
            ">3, 65/156, d1=0.501, d2=0.415 g=1.920\n",
            ">3, 66/156, d1=0.399, d2=0.688 g=2.136\n",
            ">3, 67/156, d1=0.622, d2=0.561 g=2.387\n",
            ">3, 68/156, d1=0.561, d2=0.477 g=2.291\n",
            ">3, 69/156, d1=0.616, d2=0.369 g=2.029\n",
            ">3, 70/156, d1=0.439, d2=0.429 g=2.158\n",
            ">3, 71/156, d1=0.275, d2=0.431 g=3.232\n",
            ">3, 72/156, d1=0.374, d2=0.289 g=2.579\n",
            ">3, 73/156, d1=0.611, d2=0.424 g=3.522\n",
            ">3, 74/156, d1=0.495, d2=0.356 g=1.895\n",
            ">3, 75/156, d1=0.303, d2=0.687 g=3.898\n",
            ">3, 76/156, d1=0.680, d2=0.363 g=2.227\n",
            ">3, 77/156, d1=0.406, d2=0.337 g=3.018\n",
            ">3, 78/156, d1=0.466, d2=0.373 g=2.047\n",
            ">3, 79/156, d1=0.568, d2=0.465 g=3.228\n",
            ">3, 80/156, d1=0.587, d2=0.284 g=2.742\n",
            ">3, 81/156, d1=0.440, d2=0.436 g=2.592\n",
            ">3, 82/156, d1=0.394, d2=0.410 g=2.260\n",
            ">3, 83/156, d1=0.491, d2=0.444 g=2.832\n",
            ">3, 84/156, d1=0.573, d2=0.218 g=3.161\n",
            ">3, 85/156, d1=0.389, d2=0.417 g=1.932\n",
            ">3, 86/156, d1=0.338, d2=0.502 g=2.305\n",
            ">3, 87/156, d1=0.322, d2=0.470 g=2.261\n",
            ">3, 88/156, d1=0.547, d2=0.385 g=2.384\n",
            ">3, 89/156, d1=0.554, d2=0.400 g=2.226\n",
            ">3, 90/156, d1=0.374, d2=0.472 g=2.036\n",
            ">3, 91/156, d1=0.444, d2=0.396 g=2.638\n",
            ">3, 92/156, d1=0.358, d2=0.415 g=2.379\n",
            ">3, 93/156, d1=0.643, d2=0.712 g=1.752\n",
            ">3, 94/156, d1=0.396, d2=0.848 g=5.924\n",
            ">3, 95/156, d1=1.227, d2=0.571 g=1.568\n",
            ">3, 96/156, d1=0.343, d2=0.536 g=2.127\n",
            ">3, 97/156, d1=0.443, d2=0.407 g=2.304\n",
            ">3, 98/156, d1=0.526, d2=0.407 g=2.240\n",
            ">3, 99/156, d1=0.533, d2=0.439 g=2.179\n",
            ">3, 100/156, d1=0.443, d2=0.442 g=2.538\n",
            ">3, 101/156, d1=0.380, d2=0.265 g=2.612\n",
            ">3, 102/156, d1=0.559, d2=0.428 g=2.389\n",
            ">3, 103/156, d1=0.297, d2=0.542 g=2.489\n",
            ">3, 104/156, d1=0.485, d2=0.432 g=2.786\n",
            ">3, 105/156, d1=0.533, d2=0.426 g=1.794\n",
            ">3, 106/156, d1=0.531, d2=0.461 g=3.037\n",
            ">3, 107/156, d1=0.659, d2=0.394 g=1.821\n",
            ">3, 108/156, d1=0.475, d2=0.424 g=2.603\n",
            ">3, 109/156, d1=0.289, d2=0.624 g=1.822\n",
            ">3, 110/156, d1=0.510, d2=0.443 g=1.870\n",
            ">3, 111/156, d1=0.477, d2=0.364 g=2.165\n",
            ">3, 112/156, d1=0.466, d2=0.281 g=2.819\n",
            ">3, 113/156, d1=0.392, d2=0.273 g=2.868\n",
            ">3, 114/156, d1=0.374, d2=0.384 g=2.346\n",
            ">3, 115/156, d1=0.375, d2=0.477 g=3.411\n",
            ">3, 116/156, d1=0.484, d2=0.278 g=3.121\n",
            ">3, 117/156, d1=0.381, d2=0.478 g=1.904\n",
            ">3, 118/156, d1=0.345, d2=0.452 g=2.229\n",
            ">3, 119/156, d1=0.382, d2=0.463 g=2.203\n",
            ">3, 120/156, d1=0.419, d2=0.542 g=2.361\n",
            ">3, 121/156, d1=0.545, d2=0.421 g=1.694\n",
            ">3, 122/156, d1=0.466, d2=0.581 g=2.278\n",
            ">3, 123/156, d1=0.443, d2=0.416 g=2.379\n",
            ">3, 124/156, d1=0.390, d2=0.334 g=3.056\n",
            ">3, 125/156, d1=0.418, d2=0.477 g=2.514\n",
            ">3, 126/156, d1=0.150, d2=0.613 g=7.631\n",
            ">3, 127/156, d1=1.113, d2=0.584 g=1.387\n",
            ">3, 128/156, d1=0.395, d2=0.367 g=2.199\n",
            ">3, 129/156, d1=0.352, d2=0.356 g=2.501\n",
            ">3, 130/156, d1=0.395, d2=0.346 g=2.179\n",
            ">3, 131/156, d1=0.266, d2=0.430 g=1.927\n",
            ">3, 132/156, d1=0.373, d2=0.410 g=1.818\n",
            ">3, 133/156, d1=0.626, d2=0.330 g=2.077\n",
            ">3, 134/156, d1=0.492, d2=0.450 g=1.566\n",
            ">3, 135/156, d1=0.414, d2=0.424 g=2.167\n",
            ">3, 136/156, d1=0.307, d2=0.295 g=2.656\n",
            ">3, 137/156, d1=0.325, d2=0.382 g=2.013\n",
            ">3, 138/156, d1=0.449, d2=0.396 g=2.992\n",
            ">3, 139/156, d1=0.504, d2=0.232 g=2.956\n",
            ">3, 140/156, d1=0.424, d2=0.466 g=2.180\n",
            ">3, 141/156, d1=0.665, d2=0.441 g=2.338\n",
            ">3, 142/156, d1=0.552, d2=0.448 g=1.641\n",
            ">3, 143/156, d1=0.486, d2=0.429 g=2.320\n",
            ">3, 144/156, d1=0.416, d2=0.378 g=2.316\n",
            ">3, 145/156, d1=0.290, d2=0.483 g=2.990\n",
            ">3, 146/156, d1=0.434, d2=0.431 g=1.831\n",
            ">3, 147/156, d1=0.421, d2=0.482 g=1.404\n",
            ">3, 148/156, d1=0.398, d2=0.540 g=2.801\n",
            ">3, 149/156, d1=0.409, d2=0.396 g=2.685\n",
            ">3, 150/156, d1=0.375, d2=0.431 g=3.326\n",
            ">3, 151/156, d1=0.614, d2=0.328 g=1.913\n",
            ">3, 152/156, d1=0.589, d2=0.456 g=2.513\n",
            ">3, 153/156, d1=0.423, d2=0.481 g=1.825\n",
            ">3, 154/156, d1=0.369, d2=0.555 g=2.124\n",
            ">3, 155/156, d1=0.244, d2=0.340 g=2.474\n",
            ">3, 156/156, d1=0.370, d2=0.299 g=2.967\n",
            ">4, 1/156, d1=0.387, d2=0.360 g=2.599\n",
            ">4, 2/156, d1=0.479, d2=0.371 g=2.663\n",
            ">4, 3/156, d1=0.423, d2=0.239 g=2.779\n",
            ">4, 4/156, d1=0.314, d2=0.319 g=2.040\n",
            ">4, 5/156, d1=0.420, d2=0.357 g=2.691\n",
            ">4, 6/156, d1=0.394, d2=0.375 g=2.166\n",
            ">4, 7/156, d1=0.464, d2=0.602 g=2.652\n",
            ">4, 8/156, d1=0.492, d2=0.326 g=2.330\n",
            ">4, 9/156, d1=0.450, d2=0.355 g=2.254\n",
            ">4, 10/156, d1=0.505, d2=0.345 g=2.601\n",
            ">4, 11/156, d1=0.531, d2=0.522 g=2.594\n",
            ">4, 12/156, d1=0.405, d2=0.114 g=3.402\n",
            ">4, 13/156, d1=0.371, d2=0.324 g=2.907\n",
            ">4, 14/156, d1=0.422, d2=0.244 g=2.925\n",
            ">4, 15/156, d1=0.552, d2=0.373 g=2.060\n",
            ">4, 16/156, d1=0.312, d2=0.546 g=3.205\n",
            ">4, 17/156, d1=0.457, d2=0.511 g=2.490\n",
            ">4, 18/156, d1=0.420, d2=0.457 g=2.193\n",
            ">4, 19/156, d1=0.475, d2=0.360 g=2.925\n",
            ">4, 20/156, d1=0.335, d2=0.363 g=3.089\n",
            ">4, 21/156, d1=0.308, d2=0.424 g=5.555\n",
            ">4, 22/156, d1=0.258, d2=0.368 g=4.527\n",
            ">4, 23/156, d1=0.771, d2=0.551 g=3.208\n",
            ">4, 24/156, d1=0.795, d2=0.485 g=2.432\n",
            ">4, 25/156, d1=0.462, d2=0.485 g=1.681\n",
            ">4, 26/156, d1=0.380, d2=0.558 g=2.678\n",
            ">4, 27/156, d1=0.478, d2=0.351 g=2.233\n",
            ">4, 28/156, d1=0.239, d2=0.440 g=2.523\n",
            ">4, 29/156, d1=0.244, d2=0.356 g=2.499\n",
            ">4, 30/156, d1=0.497, d2=0.349 g=2.807\n",
            ">4, 31/156, d1=0.468, d2=0.517 g=2.948\n",
            ">4, 32/156, d1=0.572, d2=0.295 g=4.000\n",
            ">4, 33/156, d1=0.440, d2=0.403 g=2.363\n",
            ">4, 34/156, d1=0.464, d2=0.431 g=3.458\n",
            ">4, 35/156, d1=0.395, d2=0.276 g=3.283\n",
            ">4, 36/156, d1=0.524, d2=0.545 g=2.120\n",
            ">4, 37/156, d1=0.384, d2=0.472 g=2.540\n",
            ">4, 38/156, d1=0.295, d2=0.463 g=2.833\n",
            ">4, 39/156, d1=0.350, d2=0.845 g=4.583\n",
            ">4, 40/156, d1=0.629, d2=0.501 g=1.659\n",
            ">4, 41/156, d1=0.435, d2=0.458 g=1.644\n",
            ">4, 42/156, d1=0.408, d2=0.397 g=2.263\n",
            ">4, 43/156, d1=0.486, d2=0.363 g=2.363\n",
            ">4, 44/156, d1=0.512, d2=0.369 g=1.879\n",
            ">4, 45/156, d1=0.383, d2=0.517 g=1.577\n",
            ">4, 46/156, d1=0.527, d2=0.353 g=2.102\n",
            ">4, 47/156, d1=0.348, d2=0.238 g=2.777\n",
            ">4, 48/156, d1=0.419, d2=0.448 g=1.889\n",
            ">4, 49/156, d1=0.328, d2=0.498 g=2.485\n",
            ">4, 50/156, d1=0.297, d2=0.290 g=3.355\n",
            ">4, 51/156, d1=0.505, d2=0.364 g=2.007\n",
            ">4, 52/156, d1=0.408, d2=0.441 g=4.149\n",
            ">4, 53/156, d1=0.538, d2=0.390 g=2.468\n",
            ">4, 54/156, d1=0.403, d2=0.680 g=3.455\n",
            ">4, 55/156, d1=0.568, d2=0.462 g=1.821\n",
            ">4, 56/156, d1=0.352, d2=0.621 g=2.926\n",
            ">4, 57/156, d1=0.511, d2=0.280 g=2.741\n",
            ">4, 58/156, d1=0.540, d2=0.424 g=2.387\n",
            ">4, 59/156, d1=0.534, d2=0.306 g=2.414\n",
            ">4, 60/156, d1=0.541, d2=0.289 g=2.651\n",
            ">4, 61/156, d1=0.393, d2=0.328 g=2.459\n",
            ">4, 62/156, d1=0.350, d2=0.479 g=1.941\n",
            ">4, 63/156, d1=0.565, d2=0.343 g=2.740\n",
            ">4, 64/156, d1=0.504, d2=0.365 g=1.999\n",
            ">4, 65/156, d1=0.510, d2=0.488 g=2.018\n",
            ">4, 66/156, d1=0.469, d2=0.287 g=2.750\n",
            ">4, 67/156, d1=0.549, d2=0.444 g=2.380\n",
            ">4, 68/156, d1=0.384, d2=0.601 g=3.297\n",
            ">4, 69/156, d1=0.646, d2=0.474 g=1.775\n",
            ">4, 70/156, d1=0.363, d2=0.434 g=2.437\n",
            ">4, 71/156, d1=0.494, d2=0.411 g=2.485\n",
            ">4, 72/156, d1=0.503, d2=0.410 g=2.866\n",
            ">4, 73/156, d1=0.561, d2=0.301 g=2.432\n",
            ">4, 74/156, d1=0.346, d2=0.368 g=1.981\n",
            ">4, 75/156, d1=0.268, d2=0.373 g=2.635\n",
            ">4, 76/156, d1=0.369, d2=0.365 g=2.433\n",
            ">4, 77/156, d1=0.465, d2=0.609 g=2.603\n",
            ">4, 78/156, d1=0.555, d2=0.362 g=2.384\n",
            ">4, 79/156, d1=0.426, d2=0.641 g=3.362\n",
            ">4, 80/156, d1=0.599, d2=0.414 g=2.165\n",
            ">4, 81/156, d1=0.445, d2=0.445 g=2.283\n",
            ">4, 82/156, d1=0.350, d2=0.355 g=2.249\n",
            ">4, 83/156, d1=0.503, d2=0.357 g=2.122\n",
            ">4, 84/156, d1=0.303, d2=0.430 g=2.196\n",
            ">4, 85/156, d1=0.586, d2=0.175 g=3.187\n",
            ">4, 86/156, d1=0.451, d2=0.499 g=1.547\n",
            ">4, 87/156, d1=0.523, d2=0.550 g=2.655\n",
            ">4, 88/156, d1=0.486, d2=0.360 g=2.200\n",
            ">4, 89/156, d1=0.596, d2=0.404 g=1.919\n",
            ">4, 90/156, d1=0.512, d2=0.403 g=2.334\n",
            ">4, 91/156, d1=0.181, d2=0.358 g=2.190\n",
            ">4, 92/156, d1=0.453, d2=0.265 g=3.127\n",
            ">4, 93/156, d1=0.452, d2=0.181 g=2.805\n",
            ">4, 94/156, d1=0.465, d2=0.238 g=3.011\n",
            ">4, 95/156, d1=0.474, d2=0.434 g=2.676\n",
            ">4, 96/156, d1=0.294, d2=0.381 g=2.492\n",
            ">4, 97/156, d1=0.312, d2=0.429 g=1.938\n",
            ">4, 98/156, d1=0.201, d2=0.594 g=2.827\n",
            ">4, 99/156, d1=0.454, d2=0.383 g=2.612\n",
            ">4, 100/156, d1=0.644, d2=0.591 g=2.139\n",
            ">4, 101/156, d1=0.301, d2=0.407 g=2.308\n",
            ">4, 102/156, d1=0.447, d2=0.338 g=2.550\n",
            ">4, 103/156, d1=0.500, d2=0.333 g=2.789\n",
            ">4, 104/156, d1=0.485, d2=0.326 g=2.573\n",
            ">4, 105/156, d1=0.458, d2=0.541 g=2.901\n",
            ">4, 106/156, d1=0.512, d2=0.480 g=1.560\n",
            ">4, 107/156, d1=0.509, d2=0.483 g=2.874\n",
            ">4, 108/156, d1=0.658, d2=0.175 g=2.934\n",
            ">4, 109/156, d1=0.488, d2=0.342 g=2.356\n",
            ">4, 110/156, d1=0.250, d2=0.251 g=3.282\n",
            ">4, 111/156, d1=0.436, d2=0.397 g=2.433\n",
            ">4, 112/156, d1=0.431, d2=0.318 g=2.294\n",
            ">4, 113/156, d1=0.396, d2=0.221 g=3.150\n",
            ">4, 114/156, d1=0.512, d2=0.442 g=1.961\n",
            ">4, 115/156, d1=0.469, d2=0.442 g=2.455\n",
            ">4, 116/156, d1=0.364, d2=0.509 g=2.279\n",
            ">4, 117/156, d1=0.461, d2=0.336 g=3.046\n",
            ">4, 118/156, d1=0.347, d2=0.207 g=2.987\n",
            ">4, 119/156, d1=0.459, d2=0.287 g=2.930\n",
            ">4, 120/156, d1=0.383, d2=0.398 g=2.670\n",
            ">4, 121/156, d1=0.484, d2=0.481 g=2.104\n",
            ">4, 122/156, d1=0.484, d2=0.521 g=3.184\n",
            ">4, 123/156, d1=0.602, d2=0.419 g=1.445\n",
            ">4, 124/156, d1=0.397, d2=0.667 g=2.001\n",
            ">4, 125/156, d1=0.401, d2=0.274 g=2.886\n",
            ">4, 126/156, d1=0.451, d2=0.293 g=2.410\n",
            ">4, 127/156, d1=0.348, d2=0.380 g=2.611\n",
            ">4, 128/156, d1=0.279, d2=0.366 g=2.510\n",
            ">4, 129/156, d1=0.525, d2=0.348 g=2.502\n",
            ">4, 130/156, d1=0.490, d2=0.392 g=2.200\n",
            ">4, 131/156, d1=0.371, d2=0.615 g=3.222\n",
            ">4, 132/156, d1=0.524, d2=0.191 g=3.211\n",
            ">4, 133/156, d1=0.521, d2=0.571 g=2.948\n",
            ">4, 134/156, d1=0.562, d2=0.372 g=3.064\n",
            ">4, 135/156, d1=0.520, d2=0.396 g=2.463\n",
            ">4, 136/156, d1=0.307, d2=0.429 g=2.784\n",
            ">4, 137/156, d1=0.417, d2=0.396 g=2.496\n",
            ">4, 138/156, d1=0.398, d2=0.410 g=3.291\n",
            ">4, 139/156, d1=0.584, d2=0.324 g=2.577\n",
            ">4, 140/156, d1=0.553, d2=0.511 g=2.492\n",
            ">4, 141/156, d1=0.646, d2=0.465 g=1.860\n",
            ">4, 142/156, d1=0.468, d2=0.499 g=1.775\n",
            ">4, 143/156, d1=0.436, d2=0.457 g=2.329\n",
            ">4, 144/156, d1=0.212, d2=0.288 g=3.216\n",
            ">4, 145/156, d1=0.257, d2=0.286 g=2.725\n",
            ">4, 146/156, d1=0.597, d2=0.430 g=2.379\n",
            ">4, 147/156, d1=0.469, d2=0.441 g=2.136\n",
            ">4, 148/156, d1=0.540, d2=0.461 g=2.495\n",
            ">4, 149/156, d1=0.414, d2=0.535 g=1.846\n",
            ">4, 150/156, d1=0.512, d2=0.624 g=2.130\n",
            ">4, 151/156, d1=0.361, d2=0.312 g=2.982\n",
            ">4, 152/156, d1=0.399, d2=0.408 g=2.103\n",
            ">4, 153/156, d1=0.478, d2=0.439 g=2.902\n",
            ">4, 154/156, d1=0.355, d2=0.561 g=1.284\n",
            ">4, 155/156, d1=0.242, d2=1.110 g=1.549\n",
            ">4, 156/156, d1=0.393, d2=0.422 g=3.432\n",
            ">Accuracy real: 0%, fake: 0%\n",
            ">5, 1/156, d1=0.697, d2=0.016 g=4.057\n",
            ">5, 2/156, d1=0.489, d2=0.394 g=2.028\n",
            ">5, 3/156, d1=0.411, d2=0.548 g=2.105\n",
            ">5, 4/156, d1=0.513, d2=0.376 g=2.378\n",
            ">5, 5/156, d1=0.517, d2=0.470 g=2.164\n",
            ">5, 6/156, d1=0.483, d2=0.438 g=2.102\n",
            ">5, 7/156, d1=0.407, d2=0.358 g=2.850\n",
            ">5, 8/156, d1=0.576, d2=0.427 g=1.761\n",
            ">5, 9/156, d1=0.330, d2=0.547 g=2.130\n",
            ">5, 10/156, d1=0.396, d2=0.342 g=2.431\n",
            ">5, 11/156, d1=0.404, d2=0.395 g=2.385\n",
            ">5, 12/156, d1=0.403, d2=0.364 g=2.470\n",
            ">5, 13/156, d1=0.459, d2=0.337 g=3.603\n",
            ">5, 14/156, d1=0.438, d2=0.381 g=1.927\n",
            ">5, 15/156, d1=0.408, d2=0.618 g=2.862\n",
            ">5, 16/156, d1=0.477, d2=0.355 g=2.562\n",
            ">5, 17/156, d1=0.070, d2=0.483 g=3.133\n",
            ">5, 18/156, d1=0.543, d2=0.340 g=2.607\n",
            ">5, 19/156, d1=0.317, d2=0.454 g=2.544\n",
            ">5, 20/156, d1=0.494, d2=0.294 g=3.000\n",
            ">5, 21/156, d1=0.597, d2=0.420 g=2.514\n",
            ">5, 22/156, d1=0.399, d2=0.484 g=2.239\n",
            ">5, 23/156, d1=0.357, d2=0.406 g=2.536\n",
            ">5, 24/156, d1=0.359, d2=0.447 g=2.276\n",
            ">5, 25/156, d1=0.345, d2=0.459 g=2.230\n",
            ">5, 26/156, d1=0.312, d2=0.352 g=2.516\n",
            ">5, 27/156, d1=0.377, d2=0.430 g=2.544\n",
            ">5, 28/156, d1=0.465, d2=0.370 g=2.427\n",
            ">5, 29/156, d1=0.463, d2=0.465 g=1.676\n",
            ">5, 30/156, d1=0.472, d2=0.716 g=2.473\n",
            ">5, 31/156, d1=0.544, d2=0.441 g=1.989\n",
            ">5, 32/156, d1=0.254, d2=0.576 g=3.121\n",
            ">5, 33/156, d1=0.449, d2=0.184 g=3.305\n",
            ">5, 34/156, d1=0.402, d2=0.440 g=2.320\n",
            ">5, 35/156, d1=0.385, d2=0.600 g=2.656\n",
            ">5, 36/156, d1=0.349, d2=0.457 g=2.100\n",
            ">5, 37/156, d1=0.490, d2=0.342 g=3.131\n",
            ">5, 38/156, d1=0.472, d2=0.391 g=2.140\n",
            ">5, 39/156, d1=0.504, d2=0.407 g=1.989\n",
            ">5, 40/156, d1=0.528, d2=0.381 g=2.259\n",
            ">5, 41/156, d1=0.297, d2=0.363 g=2.229\n",
            ">5, 42/156, d1=0.316, d2=0.284 g=3.699\n",
            ">5, 43/156, d1=0.391, d2=0.366 g=2.000\n",
            ">5, 44/156, d1=0.310, d2=0.562 g=2.921\n",
            ">5, 45/156, d1=0.459, d2=0.333 g=2.480\n",
            ">5, 46/156, d1=0.489, d2=0.404 g=2.590\n",
            ">5, 47/156, d1=0.494, d2=0.403 g=2.238\n",
            ">5, 48/156, d1=0.446, d2=0.483 g=3.071\n",
            ">5, 49/156, d1=0.432, d2=0.322 g=2.856\n",
            ">5, 50/156, d1=0.581, d2=0.365 g=2.855\n",
            ">5, 51/156, d1=0.451, d2=0.364 g=3.494\n",
            ">5, 52/156, d1=0.277, d2=0.403 g=2.041\n",
            ">5, 53/156, d1=0.270, d2=0.917 g=3.389\n",
            ">5, 54/156, d1=0.486, d2=0.411 g=2.373\n",
            ">5, 55/156, d1=0.489, d2=0.496 g=2.211\n",
            ">5, 56/156, d1=0.588, d2=0.327 g=2.432\n",
            ">5, 57/156, d1=0.502, d2=0.419 g=1.938\n",
            ">5, 58/156, d1=0.317, d2=0.468 g=2.463\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
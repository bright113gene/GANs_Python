{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape=(28,28,1)):\n",
    "    init = keras.initializers.RandomNormal(stddev=0.02)\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init,\n",
    "    input_shape=in_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(1, activation='linear', kernel_initializer=init))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    init = keras.initializers.RandomNormal(stddev=0.02)\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    n_nodes = 256 * 7 * 7\n",
    "    model.add(keras.layers.Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Reshape((7, 7, 256)))\n",
    "    # upsample to 14x14\n",
    "    \n",
    "    model.add(keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same',\n",
    "    kernel_initializer=init))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    # upsample to 28x28\n",
    "    \n",
    "    model.add(keras.layers.Conv2DTranspose(64, (4,4), strides=(2,2), padding='same',\n",
    "    kernel_initializer=init))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    # output 28x28x1\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(1, (7,7), padding='same', kernel_initializer=init))\n",
    "    model.add(keras.layers.Activation('tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples():\n",
    "    (trainX, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "    X = np.expand_dims(trainX, axis=-1)\n",
    "    X = X.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    \n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X + 1) / 2.0\n",
    "    for i in range(10 * 10):\n",
    "        pyplot.subplot(10, 10, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
    "    filename1 = 'generated_plot_%06d.png' % (step+1)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    # save the generator model\n",
    "    filename2 = 'model_%06d.h5' % (step+1)\n",
    "    g_model.save(filename2)\n",
    "    print('Saved %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(d1_hist, d2_hist, g_hist):\n",
    "    pyplot.plot(d1_hist, label='dloss1')\n",
    "    pyplot.plot(d2_hist, label='dloss2')\n",
    "    pyplot.plot(g_hist, label='gloss')\n",
    "    pyplot.legend()\n",
    "    filename = 'plot_line_plot_loss.png'\n",
    "    pyplot.savefig(filename)\n",
    "    pyplot.close()\n",
    "    print('Saved %s' % (filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=20, n_batch=64):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    half_batch = int(n_batch / 2)\n",
    "    d1_hist, d2_hist, g_hist = list(), list(), list()\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        \n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        y_real2 = np.ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        \n",
    "        print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        \n",
    "        d1_hist.append(d_loss1)\n",
    "        d2_hist.append(d_loss2)\n",
    "        g_hist.append(g_loss)\n",
    "        \n",
    "        if (i+1) % (bat_per_epo * 1) == 0:\n",
    "            summarize_performance(i, g_model, latent_dim)\n",
    "        plot_history(d1_hist, d2_hist, g_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      ">1, d1=2.428, d2=0.174 g=1.131\n",
      "Saved plot_line_plot_loss.png\n",
      ">2, d1=1.731, d2=0.347 g=1.025\n",
      "Saved plot_line_plot_loss.png\n",
      ">3, d1=0.726, d2=0.287 g=0.989\n",
      "Saved plot_line_plot_loss.png\n",
      ">4, d1=0.839, d2=0.388 g=0.640\n",
      "Saved plot_line_plot_loss.png\n",
      ">5, d1=0.852, d2=0.298 g=1.277\n",
      "Saved plot_line_plot_loss.png\n",
      ">6, d1=0.349, d2=0.149 g=1.068\n",
      "Saved plot_line_plot_loss.png\n",
      ">7, d1=0.370, d2=0.174 g=0.886\n",
      "Saved plot_line_plot_loss.png\n",
      ">8, d1=0.261, d2=0.214 g=0.738\n",
      "Saved plot_line_plot_loss.png\n",
      ">9, d1=0.526, d2=0.136 g=0.540\n",
      "Saved plot_line_plot_loss.png\n",
      ">10, d1=0.651, d2=0.139 g=0.630\n",
      "Saved plot_line_plot_loss.png\n",
      ">11, d1=0.853, d2=0.100 g=0.638\n",
      "Saved plot_line_plot_loss.png\n",
      ">12, d1=0.627, d2=0.109 g=0.498\n",
      "Saved plot_line_plot_loss.png\n",
      ">13, d1=0.421, d2=0.166 g=0.377\n",
      "Saved plot_line_plot_loss.png\n",
      ">14, d1=0.229, d2=0.264 g=0.726\n",
      "Saved plot_line_plot_loss.png\n",
      ">15, d1=0.299, d2=0.295 g=0.277\n",
      "Saved plot_line_plot_loss.png\n",
      ">16, d1=0.277, d2=0.504 g=0.704\n",
      "Saved plot_line_plot_loss.png\n",
      ">17, d1=0.337, d2=0.699 g=1.003\n",
      "Saved plot_line_plot_loss.png\n",
      ">18, d1=0.200, d2=0.693 g=0.593\n",
      "Saved plot_line_plot_loss.png\n",
      ">19, d1=0.353, d2=0.608 g=0.396\n",
      "Saved plot_line_plot_loss.png\n",
      ">20, d1=0.227, d2=0.531 g=0.608\n",
      "Saved plot_line_plot_loss.png\n",
      ">21, d1=0.265, d2=0.479 g=0.606\n",
      "Saved plot_line_plot_loss.png\n",
      ">22, d1=0.481, d2=0.207 g=0.198\n",
      "Saved plot_line_plot_loss.png\n",
      ">23, d1=0.530, d2=0.153 g=0.288\n",
      "Saved plot_line_plot_loss.png\n",
      ">24, d1=0.415, d2=0.101 g=0.491\n",
      "Saved plot_line_plot_loss.png\n",
      ">25, d1=0.567, d2=0.115 g=0.244\n",
      "Saved plot_line_plot_loss.png\n",
      ">26, d1=0.683, d2=0.397 g=0.347\n",
      "Saved plot_line_plot_loss.png\n",
      ">27, d1=0.498, d2=0.508 g=0.430\n",
      "Saved plot_line_plot_loss.png\n",
      ">28, d1=0.461, d2=1.050 g=0.885\n",
      "Saved plot_line_plot_loss.png\n",
      ">29, d1=0.315, d2=1.183 g=0.719\n",
      "Saved plot_line_plot_loss.png\n",
      ">30, d1=0.210, d2=0.948 g=0.384\n",
      "Saved plot_line_plot_loss.png\n",
      ">31, d1=0.099, d2=0.744 g=0.455\n",
      "Saved plot_line_plot_loss.png\n",
      ">32, d1=0.170, d2=0.304 g=0.238\n",
      "Saved plot_line_plot_loss.png\n",
      ">33, d1=0.182, d2=0.223 g=0.290\n",
      "Saved plot_line_plot_loss.png\n",
      ">34, d1=0.205, d2=0.160 g=0.217\n",
      "Saved plot_line_plot_loss.png\n",
      ">35, d1=0.136, d2=0.147 g=0.259\n",
      "Saved plot_line_plot_loss.png\n",
      ">36, d1=0.322, d2=0.116 g=0.183\n",
      "Saved plot_line_plot_loss.png\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "discriminator = define_discriminator()\n",
    "generator = define_generator(latent_dim)\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "dataset = load_real_samples()\n",
    "print(dataset.shape)\n",
    "train(generator, discriminator, gan_model, dataset, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

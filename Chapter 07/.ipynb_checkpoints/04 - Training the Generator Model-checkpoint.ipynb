{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Model Synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, dis_model):\n",
    "    dis_model.trainable = False\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(dis_model)\n",
    "    opt = keras.optimizers.adam(learning_rate= 0.0002,\n",
    "                                beta_1= 0.5)\n",
    "    \n",
    "    model.compile(loss= 'binary_crossentropy',\n",
    "                  optimizer= opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator and Generator Model Synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units= 128 * 7 * 7,\n",
    "                                 input_dim= latent_dim))\n",
    "    model.add(keras.layers.Reshape((7, 7, 128)))\n",
    "    \n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           strides= (2,2),\n",
    "                                           padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           strides= (2,2),\n",
    "                                           padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Conv2D(filters= 1,\n",
    "                                  kernel_size= (7,7),\n",
    "                                  activation= 'sigmoid',\n",
    "                                  padding= 'same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape= (28,28,1)):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(filters= 64,\n",
    "                                  strides= (2,2),\n",
    "                                  kernel_size= (3, 3),\n",
    "                                  padding= 'same',\n",
    "                                  input_shape= input_shape))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Conv2D(filters= 64,\n",
    "                                  strides= (2,2),\n",
    "                                  kernel_size= (3, 3),\n",
    "                                  padding= 'same',\n",
    "                                  input_shape= input_shape))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units= 1,\n",
    "                                 activation= 'sigmoid'))\n",
    "    opt = keras.optimizers.adam(learning_rate= 0.0002, beta_1= 0.5)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the models altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 28, 28, 1)         1164289   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 40705     \n",
      "=================================================================\n",
      "Total params: 1,204,994\n",
      "Trainable params: 1,164,289\n",
      "Non-trainable params: 40,705\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "g_model = define_generator(latent_dim= latent_dim)\n",
    "d_model = define_discriminator()\n",
    "model = define_gan(g_model= g_model,\n",
    "                   dis_model= d_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Real Exampels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data():\n",
    "    (X_train, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "    X_train = np.expand_dims(X_train, axis= -1).astype('float32') / 255.0\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Fake Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape((n_samples, latent_dim))\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    X = generate_latent_points(latent_dim= latent_dim,\n",
    "                               n_samples= n_samples)\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan_model, g_model, d_model, dataset, latent_dim, iters= 200, batch_size= 256):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    batch_per_epoch = dataset.shape[0]/batch_size\n",
    "    for i in range(iters):\n",
    "        for j in range(batch_per_epoch):\n",
    "            X_real, y_real = generate_real_samples(half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(half_batch)\n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack(y_real, y_fake)\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            \n",
    "            x_input = generate_latent_points(latent_dim,\n",
    "                                             batch_size= batch_size)\n",
    "            X_gan = g_model.predict(x_input)\n",
    "            y_gan = np.ones((n_samples, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            if not j%10:\n",
    "                print(f'Discriminator Loss is {d_loss}, Generator Loss is {g_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

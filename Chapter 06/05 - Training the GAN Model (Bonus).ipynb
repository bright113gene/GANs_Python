{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator and Discriminator Model Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_inputs= 2):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units= 100,\n",
    "                                 input_dim= n_inputs,\n",
    "                                 kernel_initializer= 'he_uniform'))\n",
    "    model.add(keras.layers.LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(keras.layers.Dense(units= 50,\n",
    "                                 input_dim= n_inputs,\n",
    "                                 activation= 'tanh',\n",
    "                                 kernel_initializer= 'he_uniform'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(units= 1,\n",
    "                                 activation= 'sigmoid'))\n",
    "    model.compile(loss= 'binary_crossentropy',\n",
    "                  optimizer= 'adam',\n",
    "                  metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim, n_outputs= 2):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units= 100,\n",
    "                                 input_dim= latent_dim,\n",
    "                                 kernel_initializer= 'he_uniform'))\n",
    "    model.add(keras.layers.LeakyReLU(0.1))\n",
    "    \n",
    "    model.add(keras.layers.Dense(units= 50,\n",
    "                                 activation= 'tanh',\n",
    "                                 kernel_initializer= 'he_uniform'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(units= n_outputs,\n",
    "                                 activation= 'linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Model Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= 'adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_sample(n):\n",
    "    X1 = 4 * (np.random.rand(n))\n",
    "    X2 = np.cos(np.pi * X1)\n",
    "    X1 = X1.reshape((n, 1))\n",
    "    X2 = X2.reshape((n, 1))\n",
    "    X = np.hstack((X1, X2))\n",
    "    y = np.ones((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n):\n",
    "    x_input = np.random.rand(latent_dim * n)\n",
    "    x_input = x_input.reshape((n, latent_dim))\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_sample(generator, latent_dim, n):\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "    X = generator.predict(x_input)\n",
    "    y = np.zeros((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n = 200):\n",
    "    X_real, y_real = generate_real_sample(n)\n",
    "    X_fake, y_fake = generate_fake_sample(generator= generator,\n",
    "                                          latent_dim= latent_dim,\n",
    "                                          n = n)\n",
    "    _, acc_real = discriminator.evaluate(X_real, y_real, verbose= 0)\n",
    "    _, acc_fake = discriminator.evaluate(X_fake, y_fake, verbose= 0)\n",
    "    print(f'Epoch: {epoch + 1}, Acc_real: {acc_real}, Acc_fake: {acc_fake}')\n",
    "    plt.scatter(X_real[:,0], X_real[:,1], color= 'red')\n",
    "    plt.scatter(X_fake[:,0], X_fake[:,1], color= 'blue')\n",
    "    file_name= f'Eval_Epoch{epoch + 1}.png'\n",
    "    plt.savefig(file_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, GAN_model, latent_dim, n_batch= 512, epochs = 50000):\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(epochs):\n",
    "        X_real, y_real = generate_real_sample(half_batch)\n",
    "        X_fake, y_fake = generate_fake_sample(generator= g_model,\n",
    "                                              latent_dim= latent_dim,\n",
    "                                              n= half_batch)\n",
    "        d_model.train_on_batch(X_real, y_real)\n",
    "        d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        GAN_model.train_on_batch(X_gan, y_gan)\n",
    "        \n",
    "        if (i+1)%2000 == 0:\n",
    "            summarize_performance(epoch= i,\n",
    "                                  generator= g_model,\n",
    "                                  discriminator= d_model,\n",
    "                                  latent_dim= latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000, Acc_real: 0.33000001311302185, Acc_fake: 0.9300000071525574\n",
      "Epoch: 4000, Acc_real: 0.36000001430511475, Acc_fake: 0.9750000238418579\n",
      "Epoch: 6000, Acc_real: 0.6499999761581421, Acc_fake: 0.6800000071525574\n",
      "Epoch: 8000, Acc_real: 0.41499999165534973, Acc_fake: 0.8199999928474426\n",
      "Epoch: 10000, Acc_real: 0.27000001072883606, Acc_fake: 0.8050000071525574\n",
      "Epoch: 12000, Acc_real: 0.5899999737739563, Acc_fake: 0.4449999928474426\n",
      "Epoch: 14000, Acc_real: 0.41499999165534973, Acc_fake: 0.5350000262260437\n",
      "Epoch: 16000, Acc_real: 0.38499999046325684, Acc_fake: 0.6949999928474426\n",
      "Epoch: 18000, Acc_real: 0.5600000023841858, Acc_fake: 0.7149999737739563\n",
      "Epoch: 20000, Acc_real: 0.7300000190734863, Acc_fake: 0.3149999976158142\n",
      "Epoch: 22000, Acc_real: 0.5550000071525574, Acc_fake: 0.5450000166893005\n",
      "Epoch: 24000, Acc_real: 0.7099999785423279, Acc_fake: 0.3499999940395355\n",
      "Epoch: 26000, Acc_real: 0.4950000047683716, Acc_fake: 0.5149999856948853\n",
      "Epoch: 28000, Acc_real: 0.4099999964237213, Acc_fake: 0.7099999785423279\n",
      "Epoch: 30000, Acc_real: 0.7549999952316284, Acc_fake: 0.2800000011920929\n",
      "Epoch: 32000, Acc_real: 0.4000000059604645, Acc_fake: 0.574999988079071\n",
      "Epoch: 34000, Acc_real: 0.5400000214576721, Acc_fake: 0.46000000834465027\n",
      "Epoch: 36000, Acc_real: 0.38499999046325684, Acc_fake: 0.7099999785423279\n",
      "Epoch: 38000, Acc_real: 0.6850000023841858, Acc_fake: 0.36000001430511475\n",
      "Epoch: 40000, Acc_real: 0.3199999928474426, Acc_fake: 0.7350000143051147\n",
      "Epoch: 42000, Acc_real: 0.4950000047683716, Acc_fake: 0.42500001192092896\n",
      "Epoch: 44000, Acc_real: 0.47999998927116394, Acc_fake: 0.49000000953674316\n",
      "Epoch: 46000, Acc_real: 0.6850000023841858, Acc_fake: 0.4300000071525574\n",
      "Epoch: 48000, Acc_real: 0.625, Acc_fake: 0.5799999833106995\n",
      "Epoch: 50000, Acc_real: 0.38999998569488525, Acc_fake: 0.6399999856948853\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 10\n",
    "gen_model = define_generator(latent_dim= latent_dim)\n",
    "dis_model = define_discriminator()\n",
    "gan_model = define_gan(gen_model, dis_model)\n",
    "train(g_model= gen_model, d_model= dis_model, GAN_model= gan_model, latent_dim= latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

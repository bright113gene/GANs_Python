{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_GAN(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = keras.optimizers.adam(learning_rate= 0.0002,\n",
    "                                beta_1= 0.5)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape= (32,32,3)):\n",
    "    model = keras.models.Sequential()\n",
    "    # Input is a 32*32*3 image\n",
    "    model.add(keras.layers.Conv2D(filters= 64,\n",
    "                                  kernel_size= (3,3),\n",
    "                                  padding= 'same',\n",
    "                                  input_shape= input_shape))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters= 64,\n",
    "                                  kernel_size= (3,3),\n",
    "                                  strides= (2,2),\n",
    "                                  padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # Input is a 16*16*3 image\n",
    "    model.add(keras.layers.Conv2D(filters= 128,\n",
    "                                  kernel_size= (4,4),\n",
    "                                  strides= (2,2),\n",
    "                                  padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # Input is a 8*8*3 image\n",
    "    model.add(keras.layers.Conv2D(filters= 256,\n",
    "                                  kernel_size= (4,4),\n",
    "                                  strides= (2,2),\n",
    "                                  padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # Input is now 4*4*3\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(units= 1,\n",
    "                                 activation= 'sigmoid'))\n",
    "    opt = keras.optimizers.adam(learning_rate= 0.0002, beta_1= 0.5)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= opt, metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units= 256 * 4 * 4, input_dim= latent_dim))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Reshape((4, 4, 256)))\n",
    "    # 8 * 8 now\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           padding= 'same',\n",
    "                                           strides= (2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    # 16 * 16 now\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           padding= 'same',\n",
    "                                           strides= (2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    # 32 * 32 now\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           padding= 'same',\n",
    "                                           strides= (2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Conv2D(filters= 3,\n",
    "                                  kernel_size= (3,3),\n",
    "                                  padding= 'same',\n",
    "                                  activation= 'tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (X_train, _), (_, _) = keras.datasets.cifar10.load_data()\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    X = np.random.randn(latent_dim * n_samples)\n",
    "    X = X.reshape((n_samples, latent_dim))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_sample(n_samples):\n",
    "    data = load_data()\n",
    "    ix = np.random.randint(0,data.shape[0], n_samples)\n",
    "    X = data[ix]\n",
    "    X = X.reshape((n_samples, 32, 32, 3)).astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_sample(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim= latent_dim,\n",
    "                                     n_samples= n_samples)\n",
    "    \n",
    "    X = g_model.predict(x_input)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing and plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(x_input, epoch, n=7):\n",
    "    x_input = (x_input + 1.0) / 2.0\n",
    "    filename = f'generated_{epoch + 1}.png'\n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, i+1)\n",
    "        plt.imshow(x_input[i,:,:,:])\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_the_model(g_model, d_model, epoch, latent_dim, n_samples):\n",
    "    X_real, y_real = generate_real_sample(n_samples= n_samples)\n",
    "    X_fake, y_fake = generate_fake_sample(g_model= g_model,\n",
    "                                          latent_dim= latent_dim,\n",
    "                                          n_samples= n_samples)\n",
    "    print(f'Accuracy on real data: {d_model.evaluate(X_real, y_real, verbose= 0)}')\n",
    "    print(f'Accuracy on fake data: {d_model.evaluate(X_fake, y_fake, verbose= 0)}')\n",
    "    filename = f'model_e_{epoch + 1}.h5'\n",
    "    save_plot(x_input= X_fake,\n",
    "              epoch= epoch)\n",
    "    \n",
    "    g_model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(gan_model, g_model, d_model, dataset_len, latent_dim, iters= 100, batch_size= 256):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    batch_per_epoch = int(dataset_len / batch_size)\n",
    "    for i in range(iters):\n",
    "        for j in range(batch_per_epoch):\n",
    "            X_real, y_real = generate_real_sample(n_samples= half_batch)\n",
    "            X_fake, y_fake = generate_fake_sample(g_model= g_model,\n",
    "                                                  latent_dim= latent_dim,\n",
    "                                                  n_samples= half_batch)\n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "            d_model.train_on_batch(X, y)\n",
    "            \n",
    "            x_gan = generate_latent_points(latent_dim= latent_dim,\n",
    "                                             n_samples= batch_size)\n",
    "            y_gan = np.ones((batch_size, 1))\n",
    "            gan_model.train_on_batch(x_gan, y_gan)\n",
    "            if not j%10:\n",
    "                print(f'Epoch: {i+1}, Batches/Epoch: {j+1}/{batch_per_epoch}')\n",
    "                summarize_the_model(g_model= g_model,\n",
    "                                    d_model= d_model,\n",
    "                                    epoch= i,\n",
    "                                    latent_dim= latent_dim,\n",
    "                                    n_samples= batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "g_model = define_generator(latent_dim= latent_dim)\n",
    "d_model = define_discriminator()\n",
    "gan_model = define_GAN(d_model= d_model,\n",
    "                       g_model= g_model)\n",
    "train_GAN(gan_model= gan_model,\n",
    "          g_model= g_model,\n",
    "          d_model= d_model,\n",
    "          dataset_len= load_data().shape[0],\n",
    "          latent_dim= latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

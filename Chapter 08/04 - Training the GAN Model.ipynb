{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Synthesizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_GAN(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = keras.optimizers.adam(learning_rate= 0.0002,\n",
    "                                beta_1= 0.5)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(input_shape= (32,32,3)):\n",
    "    model = keras.models.Sequential()\n",
    "    # Input is a 32*32*3 image\n",
    "    model.add(keras.layers.Conv2D(filters= 64,\n",
    "                                  kernel_size= (3,3),\n",
    "                                  padding= 'same',\n",
    "                                  input_shape= input_shape))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(filters= 64,\n",
    "                                  kernel_size= (3,3),\n",
    "                                  strides= (2,2),\n",
    "                                  padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # Input is a 16*16*3 image\n",
    "    model.add(keras.layers.Conv2D(filters= 128,\n",
    "                                  kernel_size= (4,4),\n",
    "                                  strides= (2,2),\n",
    "                                  padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # Input is a 8*8*3 image\n",
    "    model.add(keras.layers.Conv2D(filters= 256,\n",
    "                                  kernel_size= (4,4),\n",
    "                                  strides= (2,2),\n",
    "                                  padding= 'same'))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    \n",
    "    # Input is now 4*4*3\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.4))\n",
    "    model.add(keras.layers.Dense(units= 1,\n",
    "                                 activation= 'sigmoid'))\n",
    "    opt = keras.optimizers.adam(learning_rate= 0.0002, beta_1= 0.5)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= opt, metrics= ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(units= 256 * 4 * 4, input_dim= latent_dim))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Reshape((4, 4, 256)))\n",
    "    # 8 * 8 now\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           padding= 'same',\n",
    "                                           strides= (2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    # 16 * 16 now\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           padding= 'same',\n",
    "                                           strides= (2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    # 32 * 32 now\n",
    "    model.add(keras.layers.Conv2DTranspose(filters= 128,\n",
    "                                           kernel_size= (4,4),\n",
    "                                           padding= 'same',\n",
    "                                           strides= (2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(0.2))\n",
    "    model.add(keras.layers.Conv2D(filters= 3,\n",
    "                                  kernel_size= (3,3),\n",
    "                                  padding= 'same',\n",
    "                                  activation= 'tanh'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (X_train, _), (_, _) = keras.datasets.cifar10.load_data()\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    X = np.random.randn(latent_dim * n_samples)\n",
    "    X = X.reshape((n_samples, latent_dim))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_sample(n_samples):\n",
    "    data = load_data()\n",
    "    ix = np.random.randint(0,len(data), n_samples)\n",
    "    X = data[ix]\n",
    "    X = X.reshape((n_samples, 32, 32, 3)).astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    y = np.ones((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_sample(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim= latent_dim,\n",
    "                                     n_samples= n_samples)\n",
    "    \n",
    "    X = g_model.predict(x_input)\n",
    "    y = np.ones((n_samples, 1))\n",
    "    print(X.shape)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 32, 32, 3)         1466115   \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 1)                 698561    \n",
      "=================================================================\n",
      "Total params: 2,164,676\n",
      "Trainable params: 1,466,115\n",
      "Non-trainable params: 698,561\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "g_model, d_model = define_generator(latent_dim), define_discriminator()\n",
    "gan_model = define_GAN(g_model= g_model, d_model= d_model)\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing and plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(gan_model, g_model, d_model, dataset, latent_dim, iters= 100, batch_size= 256):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    batch_per_epoch = int(len(dataset) / batch_size)\n",
    "    for i in range(iters):\n",
    "        for j in range(batch_per_epoch):\n",
    "            X_real, y_real = generate_real_sample(n_samples= half_batch)\n",
    "            X_fake, y_fake = generate_fake_sample(g_model= g_model,\n",
    "                                                  latent_dim= latent_dim,\n",
    "                                                  n_samples= half_batch)\n",
    "            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "            d_model.train_on_batch(X, y)\n",
    "            \n",
    "            x_input = generate_latent_points(latent_dim= latent_dim,\n",
    "                                             n_samples= batch_size)\n",
    "            x_gan = g_model.predict(x_input)\n",
    "            y_gan = np.ones((batch_size, 1))\n",
    "            gan_model.train_on_batch(x_gan, y_gan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
